---
title: "R Notebook"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(mice)
set.seed(3356) 
#setwd('C:\\Users\\user\\Documents\\Database') #Change your path here
setwd('/Users/edisonlo/Desktop/Stat_project/Beijing-PM2.5Data/')
data <- read.csv('BeijingPM25.csv')
head(data)

md.pattern(data)
```

```{r}
set.seed(3356) 
#Modification on missing data code
#Replace missing value with the mean of pm2.5 in the corresponding year
dataCleaned <- data
head(dataCleaned[is.na(data$pm2.5), ])
for (i in 2010:2014){
  data.mean <- mean(dataCleaned[dataCleaned$year==i, ]$pm2.5, na.rm=T)
  dataCleaned[is.na(data$pm2.5) & dataCleaned$year==i, ]$pm2.5 <- data.mean
}

md.pattern(dataCleaned)

```

```{r}
set.seed(3356) 
#Correlation matrix of continuous variables (ContVar)
dataContVar <- data[, c(7:9, 11:13)]
cor(dataContVar)

#Interpretation DEWP, TEMP and PRES are highly correlated.
```

```{r}
set.seed(3356) 
#PCA dimension reduction
fit <- prcomp(dataContVar, scale. = T)
summary(fit) #4 pc solution, retain ~94% information

fit$rotation
#PC1: positively related to DEWP, TEMP but negative related to PRES
#PC2: negative related to Is and Ir
#PC3: negative related to Is but positively related to Ir
#Pc4: Negatively related to Iws

head(fit$x)
dataPCA <- data.frame(dataCleaned[, c(2:6, 10)], fit$x[,1:4])
head(dataPCA)
write.csv(dataPCA, file="DataCleaned.csv", row.names=FALSE)
```

```{r}
set.seed(3356) 
dataPCA$cbwd <- factor(dataPCA$cbwd, levels=c('cv', 'NE', 'NW', 'SE'))
fitlm <- lm(formula = pm2.5 ~ PC1+PC2+PC3+PC4+cbwd, data=dataPCA)
summary(fitlm)


folds <- cut(seq(1,nrow(dataPCA)),breaks=10,labels=FALSE)
cv.data <-dataPCA[sample(nrow(dataPCA)),]
cv.errors=matrix(rep( 0, len=10), nrow = 1)
#cv.errors
#Perform 10 fold cross validation

##################################################################################################
###############                    1st model:  PC1+PC2+PC3+PC4+cbwd                  #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ PC1+PC2+PC3+PC4+cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ PC1+PC2+PC3+PC4+cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.1 = mean(cv.errors)
test_mse.1

fit.lm1 <- lm(pm2.5 ~ PC1+PC2+PC3+PC4+cbwd, data=dataPCA)
summary(fit.lm1)
# Test MSE = 2.335974
# p-value < 2.2e-16 
# Adj R^2 = 0.09654
```
```{r}
set.seed(3356) 

# Do cross validation
# Randomly shuffle the data
cv.data <-dataPCA[sample(nrow(dataPCA)),]
#View(cv.data)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(dataPCA)),breaks=10,labels=FALSE)
cv.errors=matrix(rep( 0, len=10), nrow = 1)
#cv.errors
#Perform 10 fold cross validation

##################################################################################################
###############   2nd model: pm2.5 ~ poly(PC1,2) + poly(PC2,2) + PC3 + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + PC3 + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + PC3 + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.2 = mean(cv.errors)
test_mse.2

fit.lm2 <- lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + PC3 + PC4 + cbwd, data=dataPCA)
summary(fit.lm2)

# Test MSE = 1.275483
# p-value < 2.2e-16 
# Adj R^2 = 0.1047



##################################################################################################
###############   3rd model: pm2.5 ~ poly(PC1,3) + poly(PC2,2) + PC3 + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,3) + poly(PC2,2) + PC3 + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,3) + poly(PC2,2) + PC3 + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.3 = mean(cv.errors)
test_mse.3

fit.lm3 <- lm(pm2.5 ~ poly(PC1,3) + poly(PC2,2) + PC3 + PC4 + cbwd, data=dataPCA)
summary(fit.lm3)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1047

##################################################################################################
###############   4th model: pm2.5 ~ poly(PC1,3) + poly(PC2,3) + PC3 + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,3) + poly(PC2,3) + PC3 + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,3) + poly(PC2,3) + PC3 + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.4 = mean(cv.errors)
test_mse.4

fit.lm4 <- lm(pm2.5 ~ poly(PC1,3) + poly(PC2,3) + PC3 + PC4 + cbwd, data=dataPCA)
summary(fit.lm4)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1059



##################################################################################################
###############   5th model: pm2.5 ~ poly(PC1,4) + poly(PC2,3) + PC3 + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,4) + poly(PC2,3) + PC3 + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,4) + poly(PC2,3) + PC3 + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.5 = mean(cv.errors)
test_mse.5

fit.lm5 <- lm(pm2.5 ~ poly(PC1,4) + poly(PC2,3) + PC3 + PC4 + cbwd, data=dataPCA)
summary(fit.lm5)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.12


##################################################################################################
###############   6th model: pm2.5 ~ poly(PC1,4) + poly(PC2,4) + PC3 + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,4) + poly(PC2,4) + PC3 + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,4) + poly(PC2,4) + PC3 + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.6 = mean(cv.errors)
test_mse.6

fit.lm6 <- lm(pm2.5 ~ poly(PC1,4) + poly(PC2,4) + PC3 + PC4 + cbwd, data=dataPCA)
summary(fit.lm6)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1231

##################################################################################################
###############   7th model: pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.7 = mean(cv.errors)
test_mse.7

fit.lm7 <- lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) +  poly(PC3,2) + PC4 + cbwd, data=dataPCA)
summary(fit.lm7)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1048

##################################################################################################
###############   8th model: pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + poly(PC4,2) + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + poly(PC4,2) + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,2) + poly(PC4,2) + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.8 = mean(cv.errors)
test_mse.8

fit.lm8 <- lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) +  poly(PC3,2) + poly(PC4,2) + cbwd, data=dataPCA)
summary(fit.lm8)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1316



##################################################################################################
###############   9th model: pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,3) + PC4 + cbwd    #############
##################################################################################################

for(i in 1:10){
    testIndexes <- which(folds==i,arr.ind=TRUE)
    testData <- cv.data[testIndexes, ]
    trainData <- cv.data[-testIndexes, ]
   
    pred <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,3) + PC4 + cbwd, data=trainData)
    y    <-  lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) + poly(PC3,3) + PC4 + cbwd, data=testData)
    
    pred_pm2.5.predict <- predict(pred,trainData)
    y_pm2.5.predict    <- predict(y,testData)
     
    pred_pm2.5   = mean(pred_pm2.5.predict)
    y_pm2.5      = mean(y_pm2.5.predict)
    cv.errors[i] = mean((y_pm2.5-pred_pm2.5)^2)
}
test_mse.9 = mean(cv.errors)
test_mse.9

fit.lm9 <- lm(pm2.5 ~ poly(PC1,2) + poly(PC2,2) +  poly(PC3,2) + poly(PC3,3) + PC4, data=dataPCA)
summary(fit.lm9)

# Test MSE = 1.284531
# p-value < 2.2e-16 
# Adj R^2 = 0.1316


# The following code is found by using library
# but not sure how to plug in custom model
# Interested may look at 
# https://stackoverflow.com/questions/10399792/stratified-10-fold-cross-validation/23674455
# and official doc

# library(caret)
# model <- train(pm2.5 ~ .-year-month-day-hour,dataPCA, method="lm", 
#                trControl = trainControl(
#                  method = "cv", number = 10,
#                  verboseIter = TRUE
#                )
# )
# summary(model)
# 
# 
# data <- dataPCA[1:5]
# data
# nrow(dataPCA)
# train_index <- createDataPartition(dataPCA$pm2.5,
#                                    p = 0.8,
#                                    list = FALSE,
#                                    times = 10)
# head(train_index)

```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
